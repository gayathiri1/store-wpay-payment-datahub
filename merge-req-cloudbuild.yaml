steps:
# Cloudbuild only clone the current commit, it won't clone the history. 
# So added below 3 steps to clone the complete history from the Github.

# Access the id_github file from Secret Manager, and setup SSH to clone the Github repo.
- name: 'gcr.io/cloud-builders/git'
  secretEnv: ['SSH_KEY']
  entrypoint: 'bash'
  args:
  - -c
  - |
    echo 'Build:$BUILD_ID triggered after the merge to branch:${BRANCH_NAME}.'
    echo 'The commit is:$COMMIT_SHA'
    echo "$$SSH_KEY" >> /root/.ssh/id_rsa
    chmod 400 /root/.ssh/id_rsa
    cp known_hosts.github /root/.ssh/known_hosts
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# This just gets current branch history of the repository. But this will not copy/clone other branches.
- name: 'gcr.io/cloud-builders/git'
  args: 
  - fetch
  - --unshallow
  - git@github.com:w-pay/$REPO_NAME
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# list the files which are changed in the current commit/pull request.
- name: gcr.io/cloud-builders/gcloud
  entrypoint: /bin/sh
  args: 
    - '-c'
    - | 
      ls -ltra && \
      git diff --name-only HEAD~1 HEAD > /workspace/commitfiles.txt && \
      cat /workspace/commitfiles.txt

# Terraform apply after the merge.
- name: hashicorp/terraform:1.1.2
  entrypoint: sh
  args: 
  - '-c'
  - |
    cd app/terraform/
    terraform init -backend-config "bucket=${_TF_BACKEND_BUCKET}" -backend-config "prefix=${_TF_BACKEND_PREFIX}"
    # terraform workspace select ${_BASE_BRANCH} || terraform workspace new ${_BASE_BRANCH}
    terraform plan
    # terraform apply --auto-approve
    if grep "bq\/tables\/\|bq\/views\/\|bq/etl\/" /workspace/commitfiles.txt; 
    then 
      echo "bq deployment is required"; 
      if grep bq\/tables\/ /workspace/commitfiles.txt;
      then
        echo "bq table deployment is required. Also check if table backup is required."; 

      else
        echo "bq table deployment is not required in current build.";
      fi
      if grep bq\/views\/ /workspace/commitfiles.txt;
      then
        echo "bq views deployment is required."; 
      else
        echo "bq views deployment is not required in current build.";
      fi
      if grep bq\/etl\/ /workspace/commitfiles.txt;
      then
        echo "bq etl deployment is required. Also check if etl execution is required."; 
      else
        echo "bq etl deployment is not required in current build.";
      fi   
    else 
      echo "No bq files modified in current commit, hence bq deployment is not required."; 
    fi

# # Synch the Dags with the GCS bucket. It creates the directories if it doesn't exists.
# # In gsutil -c option is used to do the checksum comparison rather than mtime check, 
# # as mtime always gets changed when repo gets cloned to cloudbuild workspace. 
# # The -d option will delete files from the destination folder if they don't exist in the source folder.
# - name: gcr.io/cloud-builders/gsutil
#   entrypoint: bash
#   args: 
#   - '-c'
#   - | 
#     if [[ $(grep dags\/ /workspace/commitfiles.txt) == *dags\/*.py ]];
#      then
#       gsutil -m rsync -c -d -r dags gs://${_GCS_BUCKET}/dags;
#      else
#       echo "Dags are not modified, hence dags sync with gcs is not required.";
#     fi

# logsBucket: "gs://${_LOGS_BUCKET}"
# cloudbuild-github-ssh-key

availableSecrets:
  secretManager:
  - versionName: projects/$PROJECT_NUMBER/secrets/$REPO_NAME-github-key/versions/latest
    env: 'SSH_KEY'