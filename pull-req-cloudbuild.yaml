steps:
# Cloudbuild only clone the current commit, it won't clone the history. 
# So added below 3 steps to clone the complete history from the Github.
# Also added the Git branch name validation.
- name: 'gcr.io/cloud-builders/git'
  secretEnv: ['SSH_KEY']
  entrypoint: 'bash'
  args:
  - -c
  - |
    echo 'Build:$BUILD_ID is triggered for the Pull request:$_PR_NUMBER'
    echo 'The Base Branch is: $_BASE_BRANCH'
    echo 'The Head Branch is: $_HEAD_BRANCH'
    valid_branch_regex="^feature\/ci-cd|feature\/DATPAY-([0-9]{4})$"
    if [[ ! $_HEAD_BRANCH =~ $valid_branch_regex ]]
    then
        echo "There is something wrong with your branch name. Branch names must adhere to this contract: $valid_branch_regex. You should rename your branch to a valid name and try again."
        exit 1
    else
      echo "Git Branch name validation passed."
      echo "$$SSH_KEY" >> /root/.ssh/id_rsa
      chmod 400 /root/.ssh/id_rsa
      cp known_hosts.github /root/.ssh/known_hosts
    fi   
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# This just gets current branch history of the repository. But this will not copy/clone other branches.
- name: 'gcr.io/cloud-builders/git'
  args: 
  - fetch
  - --unshallow
  - git@github.com:w-pay/$REPO_NAME
  volumes:
  - name: 'ssh'
    path: /root/.ssh


# This to clone the whole repository including all branches.
- name: 'gcr.io/cloud-builders/git'
  args: 
  - clone
  - --recurse-submodules
  - git@github.com:w-pay/$REPO_NAME
  volumes:
  - name: 'ssh'
    path: /root/.ssh

# list the files which are changed in the current commit/pull request.
- name: gcr.io/cloud-builders/gcloud
  entrypoint: /bin/sh
  args: 
    - '-c'
    - | 
      ls -ltra
      git diff --name-only HEAD~1 HEAD > /workspace/commitfiles.txt
      echo '########## Files changed in Current Commit are listed below ##########'
      cat /workspace/commitfiles.txt
      echo '########## Commit List End ##########'
      cd $REPO_NAME
      git branch -a
      git diff --name-only remotes/origin/$_HEAD_BRANCH remotes/origin/$_BASE_BRANCH > /workspace/branchfiles.txt
      echo '########## Files changed in Pull Request are listed below ##########'
      cat /workspace/branchfiles.txt
      echo '########## Pull Request List End ##########'

# - name: hashicorp/terraform:1.1.2
#   dir: "app/terraform/"
#   args: ['init']

# # Validating the ETL 
# # 1. Check if the Table/View already exist. Then exit the pipeline with failure.
# # 2. If tables/view doesn't exit then, run the terraform plan to validate what changes are goind to heppen in bq.
# # Can refer https://cloud.google.com/architecture/managing-infrastructure-as-code for terraform invocation.
# - name: hashicorp/terraform:1.1.2
#   entrypoint: sh
#   args: 
#   - '-c'
#   - |
#     cd app/terraform/
#     terraform init -backend-config "bucket=${_TF_BACKEND_BUCKET}" -backend-config "prefix=${_TF_BACKEND_PREFIX}"
#     # terraform workspace select ${_BASE_BRANCH} || terraform workspace new ${_BASE_BRANCH}
#     terraform plan
#     if grep "bq\/tables\/\|bq\/views\/\|bq/etl\/" /workspace/commitfiles.txt  /workspace/branchfiles.txt; 
#     then 
#       echo "bq deployment is required"; 
#       if grep bq\/tables\/ /workspace/commitfiles.txt  /workspace/branchfiles.txt;
#       then
#         echo "bq table deployment is required. Also check if table is already required."; 

#       else
#         echo "bq table deployment is not required in current build.";
#       fi
#       if grep bq\/views\/ /workspace/commitfiles.txt  /workspace/branchfiles.txt;
#       then
#         echo "bq views deployment is required. Also check f the table already exist."; 
#       else
#         echo "bq views deployment is not required in current build.";
#       fi
#       if grep bq\/etl\/ /workspace/commitfiles.txt  /workspace/branchfiles.txt;
#       then
#         echo "bq etl deployment is required. Also check if etl execution is required."; 
#       else
#         echo "bq etl deployment is not required in current build.";
#       fi   
#     else 
#       echo "No bq files modified in current commit, hence bq deployment is not required."; 
#     fi

# -n option would check the difference without performing the sync 
# Synch the Dags with the GCS bucket. It creates the directories if it doesn't exists.
# In gsutil -c option is used to do the checksum comparison rather than mtime check, 
# as mtime always gets changed when repo gets cloned to cloudbuild workspace. 
# The -d option will delete files from the destination folder if they don't exist in the source folder.
# -x to exclude files.
- name: gcr.io/cloud-builders/gsutil
  entrypoint: bash
  args: 
  - '-c'
  - | 
    # if [[ $(grep dags\/ /workspace/commitfiles.txt  /workspace/branchfiles.txt) == *dags\/*.py ]];
    #  then
      echo "*********** Dags modified in the repo are list below ************"
      gsutil -m rsync -c -r -n -x "app/dags/common/airflow_monitoring.py" app/dags/common gs://${_GCS_BUCKET}/dags;
      echo "*********** Dags list end ************"
      if 
    #  else
    #   echo "Dags are not modified, hence dags sync with gcs is not required.";
    # fi

# logsBucket: "gs://${_LOGS_BUCKET}"

availableSecrets:
  secretManager:
  # - versionName: projects/$PROJECT_NUMBER/secrets/$REPO_NAME-github-key/versions/latest
  - versionName: projects/$PROJECT_NUMBER/secrets/cloudbuild-github-ssh-key/versions/latest
    env: 'SSH_KEY'